{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "E-Commerce Simulation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kklK9i6MG9k1",
        "outputId": "83de6f2a-70bf-4bc4-88f8-1ee2393b2731"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import datetime as dt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import adjusted_rand_score\n",
        "from pandas.core.common import random_state"
      ],
      "metadata": {
        "id": "--S9GcciHF8e"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Data_Standardising(X):\n",
        "\n",
        "  # standardising the data\n",
        "  scaler = StandardScaler()\n",
        "  data_scaled = scaler.fit_transform(X)\n",
        "\n",
        "  return data_scaled"
      ],
      "metadata": {
        "id": "nQ1f6_Sc9Rtw"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def KMeans_Clustering(n_clusters, scores_pca):\n",
        "\n",
        "  # defining the kmeans function with initialization as k-means++\n",
        "  kmeans = KMeans(n_clusters, init='k-means++', random_state = 42)\n",
        "\n",
        "  # fitting the k means algorithm on the data\n",
        "  kmeans_pca = kmeans.fit(scores_pca)\n",
        "\n",
        "  return kmeans_pca"
      ],
      "metadata": {
        "id": "BCPGitxu9Wm6"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def PCA_Function(X_scaled, n_components):\n",
        "\n",
        "  pca = PCA(n_components)\n",
        "\n",
        "  pca.fit(X_scaled)\n",
        "\n",
        "  pca.transform(X_scaled)\n",
        "\n",
        "  scores_pca = pca.transform(X_scaled)\n",
        "\n",
        "  return scores_pca"
      ],
      "metadata": {
        "id": "wVaCeHNX9opO"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Cluster_Evolution(frequency, df_kmeans, df, day, month, year):\n",
        "\n",
        "  # Creation of dataframe of returning customers\n",
        "  Frequent_Customers = df_kmeans.loc[df_kmeans[\"frequency\"] >= frequency]\n",
        "\n",
        "  # Creation of dataframe to test with required dates\n",
        "  Selected_Dates = Order_Dataset[Order_Dataset['Date_of_last_purchase']<dt.datetime(year,month,day)]\n",
        "\n",
        "  # Creation of dataframe with orignal data for the required dates\n",
        "  Original_Selected_Dates = Frequent_Customers[Frequent_Customers['Date_of_last_purchase']<dt.datetime(year,month,day)]\n",
        "\n",
        "  # Labels for the original selected dates\n",
        "  Labels_true = np.array(Original_Selected_Dates['Cluster'])\n",
        "\n",
        "  # Creation of dataframe with required columns for the required dates\n",
        "  Testing = Selected_Dates[['Seconds_Since_Last_Order', 'Sum_of_Prices', 'frequency']]\n",
        "\n",
        "  # Data standardising function\n",
        "  df_scaled = Data_Standardising(Testing)\n",
        "\n",
        "  # PCA function\n",
        "  scores_pca = PCA_Function(df_scaled, 3)\n",
        "\n",
        "  #KMeans\n",
        "  kmeans_pca = KMeans_Clustering(4, scores_pca)\n",
        "\n",
        "  # Dataframe creation with components and clusters\n",
        "  New_kmeans_pca = pd.concat([Selected_Dates.reset_index(drop = True), pd.DataFrame(scores_pca)], axis = 1)\n",
        "  New_kmeans_pca.columns.values[-3:] = ['Component 1', 'Component 2', 'Component 3']\n",
        "  New_kmeans_pca['Cluster'] = kmeans_pca.labels_\n",
        "\n",
        "  # Creation of new dataframe with only returning customers\n",
        "  Returning_Customers_df = New_kmeans_pca.loc[New_kmeans_pca[\"frequency\"] >= frequency]  \n",
        "  kmeans_pca.labels = np.array(Returning_Customers_df[\"Cluster\"])\n",
        "  print(adjusted_rand_score(Labels_true, kmeans_pca.labels))"
      ],
      "metadata": {
        "id": "JcfhLnkDUZ2i"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_kmeans = pd.read_csv(\"/content/drive/MyDrive/df_kmeans.csv\")\n",
        "Order_Dataset = pd.read_csv(\"/content/drive/MyDrive/Order_Dataset.csv\")"
      ],
      "metadata": {
        "id": "V6LyEx1bHWuC"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Order_Dataset.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o00dwWB_WpMM",
        "outputId": "e04362e3-86ce-4176-cd99-39ad27a4b97b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 95963 entries, 0 to 95962\n",
            "Data columns (total 17 columns):\n",
            " #   Column                         Non-Null Count  Dtype  \n",
            "---  ------                         --------------  -----  \n",
            " 0   Unnamed: 0                     95963 non-null  int64  \n",
            " 1   customer_unique_id             95963 non-null  object \n",
            " 2   Date_of_last_purchase          95963 non-null  object \n",
            " 3   last_date                      95963 non-null  object \n",
            " 4   Difference                     95963 non-null  object \n",
            " 5   Seconds_Since_Last_Order       95963 non-null  float64\n",
            " 6   Sum_of_Prices                  95963 non-null  float64\n",
            " 7   price                          95963 non-null  float64\n",
            " 8   payment_value                  95963 non-null  float64\n",
            " 9   payment_sequential             95963 non-null  float64\n",
            " 10  payment_type                   95963 non-null  object \n",
            " 11  payment_installments           95963 non-null  float64\n",
            " 12  review_score                   95963 non-null  float64\n",
            " 13  customer_zip_code_prefix       95963 non-null  int64  \n",
            " 14  product_category_name_english  95963 non-null  object \n",
            " 15  frequency                      95963 non-null  int64  \n",
            " 16  Average_Price                  95963 non-null  float64\n",
            "dtypes: float64(8), int64(3), object(6)\n",
            "memory usage: 12.4+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving to CSV file converts datetime type back to object type hence a requirement to reconvert back to datetime\n",
        "\n",
        "Order_Dataset['Date_of_last_purchase'] = pd.to_datetime(Order_Dataset['Date_of_last_purchase'])\n",
        "\n",
        "df_kmeans['Date_of_last_purchase'] = Order_Dataset['Date_of_last_purchase']"
      ],
      "metadata": {
        "id": "Sik9xvxJXU_4"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frequency = 1\n",
        "year = 2018\n",
        "month = 8\n",
        "day = 12\n",
        "\n",
        "Adjusted_Rand_Score = Cluster_Evolution(frequency, df_kmeans, Order_Dataset, day, month, year)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btCiu1C4VWjp",
        "outputId": "3671932d-8352-41b3-fac8-cfb27e2ece2c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7281672851343137\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "12/8/2018 Rand index = 0.73, 91946 customers\n",
        "\n",
        "13/8/2018 Rand index = 0.91, 92143 customers\n",
        "\n",
        "Last customer purchase = 3/9/2018\n",
        "\n",
        "Therefore new cluster simulation required every 3 weeks"
      ],
      "metadata": {
        "id": "kKWg9XM8ARiD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "frequency = 2\n",
        "year = 2018\n",
        "month = 2\n",
        "day = 14\n",
        "\n",
        "Adjusted_Rand_Score = Cluster_Evolution(frequency, df_kmeans, Order_Dataset, day, month, year)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXD_MUCGVaHn",
        "outputId": "ae7bcac5-5313-4174-f32d-1dbfffbd7290"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7777915898422755\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For returning customers the Rand Index drops below 0.8 only between 3/1/18 and 14/2/2018, therefore retraining is not needed "
      ],
      "metadata": {
        "id": "xo9yjT8VAcAJ"
      }
    }
  ]
}